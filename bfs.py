# -*- coding: utf-8 -*-
"""bfs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11E3E-xRcsRhJcbLs1qlADBfEtHH-a4P2
"""

# adapted from https://stackoverflow.com/questions/47896461/get-shortest-path-to-a-cell-in-a-2d-array-in-python
import numpy as np
import matplotlib.pyplot as plt
import time
import seaborn as sns
from sklearn.preprocessing import minmax_scale
import sys
import pdb

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !git clone https://github.com/sawcordwell/pymdptoolbox.git
# !pip install pymdptoolbox
# import mdptoolbox.example
# import time
# from google.colab import files
# import os
# from google.colab import drive
# from collections import deque

# connect to GDrive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# this function converts (x,y) to state index in (size,size) grid
# state number = coordYcoordX (0,0) is bottom left corner (size-1, size-1) is upper right corner
def coordToStateIdx(size, x, y):
  idx = size*y+x
  return idx

class Dijkstras:

  # environment setup
  def __init__(self, size):
    num_states = size ** 2
    num_actions = 4 # 1 = north, 2 = east, 3 = south, 4 = west
    env = -1 * np.ones((size, size))

    # obstacle
    obstacle_cells = []
    # walls
    for i in range(0,size):
        env[0,i] = -10
        obstacle_cells.append(coordToStateIdx(size,0,i))
        env[i,0] = -10
        obstacle_cells.append(coordToStateIdx(size,i,0))
        env[size-1,i] = -10
        obstacle_cells.append(coordToStateIdx(size,size-1,i))
        env[i,size-1] = -10
        obstacle_cells.append(coordToStateIdx(size,i,size-1))
    # clumps of obstacles
    num_obstacles = int(num_states / 30)
    for j in range(num_obstacles):
      obsX = np.random.randint(0,size)
      obsY = np.random.randint(0,size)
      env[obsX, obsY] = -10
      obstacle_cells.append(coordToStateIdx(size,obsX, obsY))
      for wall in range(3):
        intervalX = np.random.randint(-1,1)
        intervalY = np.random.randint(-1,1)
        currX = obsX+intervalX
        currY = obsY+intervalY
        env[currX, currY] = -10
        obstacle_cells.append(coordToStateIdx(size,currX, currY))
      

    # target cell
    targetX = np.random.randint(1,size-1)
    targetY = np.random.randint(1,size-1)
    env[targetX,targetY] = 10
    target_cell = 10*targetY + targetX
    r = np.flip(env,axis=0).flatten()
    # print("r\n", r)
    plt.imshow(env)
    self.env = env
    self.size = size
    self.obstacles = obstacle_cells
    sink_cells = obstacle_cells
    sink_cells.append(target_cell)
    self.sink_cells = sink_cells
    self.target_cell = target_cell
  
  # this function returns length of shortest path from 'start' to target cell (represented by -10 in 'grid') and optimal direction to take from current cell 
  def bfs(self, grid, start):
    queue = deque([[start]])
    currPoint = coordToStateIdx(self.size, start[0], start[1])
    seen = set([start])
    if currPoint in self.obstacles: # sink cell means impossible to reach target
      return -1, -1
    while queue:
        path = queue.popleft()
        x, y = path[-1]
        if grid[y][x] == -10: # target = -10 because flipped env sign to calculate shortest path
          direction = 0 # north = 0, east = 1, south = 2, west = 3
          if len(path) == 1: # target cell
            return 0,0
          nextStep = path[1]
          if nextStep[0] == start[0] and nextStep[1] == start[1] + 1:
              direction = 1
          elif nextStep[0] == start[0] and nextStep[1] == start[1] - 1:
              direction = 3
          elif nextStep[0] == start[0]  + 1 and nextStep[1] == start[1]:
              direction = 2
          return len(path), direction
        added_queue = False
        for x2, y2 in ((x+1,y), (x-1,y), (x,y+1), (x,y-1)):
            if 0 <= x2 < self.size and 0 <= y2 < self.size and grid[y2][x2] != 10 and (x2, y2) not in seen: # obstacle = 10 because flipped env sign to calculate shortest path
            # if 0 <= x2 < self.size and 0 <= y2 < self.size and (x2, y2) not in seen:
                queue.append(path + [(x2, y2)])
                seen.add((x2, y2))
                added_queue = True
        if not added_queue:
          return -1, -1
    
  # this function runs dijkstra's solution
  def run_dijk(self):
    dijk_start = time.time()
    width = self.size
    height = self.size
    dijk_reward = np.zeros((width, height))
    dijk_policy = np.zeros((width, height))
    R = -1 * self.env # make solving for shortest path = best reward by flipping all signs
    for i in range(width):
      for j in range(height):
        if coordToStateIdx(self.size, i,j) in self.obstacles:
          spt = -1; 
          dir = -1;
        else:
          spt, dir = self.bfs(R,(i,j))
        dijk_reward[i,j] = spt
        dijk_policy[i,j] = dir
    dijk_time = time.time() - dijk_start
    self.dijk_policy = dijk_policy
    self.dijk_reward = dijk_reward
    return dijk_reward, dijk_policy, dijk_time

  # Function to check if a cell is be visited or not
  def isValid(vis, row, col):
      # If cell lies out of bounds
      if (row < 0 or col < 0 or row >= 4 or col >= 4):
          return False
  
      # If cell is already visited
      if (vis[row][col]):
          return False
  
      # Otherwise
      return True

  # adapted from: https://www.geeksforgeeks.org/breadth-first-traversal-bfs-on-a-2d-array/
  def run_bfs(self):
      row = 0
      col = 0
      # Direction vectors
      dRow = [ -1, 0, 1, 0]
      dCol = [ 0, 1, 0, -1]
      vis = [[ False for i in range(self.size)] for i in range(self.size)]
      # Stores indices of the matrix cells
      q = deque()
      grid = self.env
      # Mark the starting cell as visited
      # and push it into the queue
      q.append(( row, col ))
      vis[row][col] = True

      # Iterate while the queue is not empty
      while (len(q) > 0):
          cell = q.popleft()
          x = cell[0]
          y = cell[1]
          print(grid[x][y], end = " ")
  
          #q.pop()
  
          # Go to the adjacent cells
          for i in range(4):
              adjx = x + dRow[i]
              adjy = y + dCol[i]
              if (self.isValid(vis, adjx, adjy)):
                  q.append((adjx, adjy))
                  vis[adjx][adjy] = True
 

  def get_env(self):
    return self.env

  def get_obstacles(self):
    return self.obstacles

  def get_policy(self):
    return self.dijk_policy

  def get_reward(self):
    return self.dijk_reward

  def get_target_cell(self):
    return self.target_cell

  def get_size(self):
    return self.size

  def get_sink_cells(self):
    return self.sink_cells

class MDP:

  def get_R_direction(self, R, prob_north, prob_south, prob_west, prob_east, prob_same):
    return R[:-2, 1:-1] * prob_north + R[2:, 1:-1] * prob_south + R[1:-1, :-2] * prob_west + R[1:-1, 2:] * prob_east + R[1:-1, 1:-1] * prob_same

  def updateRObstacles(self, r):
    for i in range(self.num_states):
      if i in self.obstacles:
        r[i] = -10
      if type(self.target_cell) == type(list()):
        if i in self.target_cell:
          r[i] = 10
      else:
        if i == self.target_cell:
          r[i] = 10
    return r
  
  def sanity_check(self, T_north, T_south, T_west, T_east): # Sanity check that all rows add up to one
    for i in range(self.num_states): 
      summed = np.sum(T_east[i])
      if summed < 0.99 or summed > 1.01:
        print("east", i, T_east[i])
      
      summed = np.sum(T_north[i])
      if summed < 0.99 or summed > 1.01:
        print("north", i, T_north[i])
      
      summed = np.sum(T_west[i])
      if summed < 0.99 or summed > 1.01:
        print("west", i, T_west[i])
      
      summed = np.sum(T_south[i])
      if summed < 0.99 or summed > 1.01:
        print("south", i, T_south[i])

  def __init__(self, size, env, obstacle_cells, target_cell):
    self.size = size
    self.num_states = self.size ** 2
    self.target_cell = target_cell
    self.obstacles = obstacle_cells

    # Define all states ~ Transition Matrix
    T_north = np.zeros((self.num_states,self.num_states))
    T_east = np.zeros((self.num_states,self.num_states))
    T_south = np.zeros((self.num_states,self.num_states))
    T_west = np.zeros((self.num_states,self.num_states))

    # Create R_new to pass to built-in Python function
    paddedR = np.pad(env, 1, mode='constant', constant_values=-10)
    R_north = self.get_R_direction(paddedR, 0.7, 0.0, 0.1, 0.1, 0.1)
    r_north = self.updateRObstacles(R_north.flatten())

    R_south = self.get_R_direction(paddedR, 0.0, 0.7, 0.1, 0.1, 0.1)
    r_south = self.updateRObstacles(R_south.flatten())

    R_west = self.get_R_direction(paddedR, 0.1, 0.1, 0.7, 0.0, 0.1)
    r_west = self.updateRObstacles(R_west.flatten())

    R_east = self.get_R_direction(paddedR, 0.1, 0.1, 0.0, 0.7, 0.1)
    r_east = self.updateRObstacles(R_east.flatten())

    r = np.flip(env,axis=0).flatten()

    # obstacles and target cells are sink cells 
    sink_cells = self.obstacles
    if type(target_cell) == type(list()):
      sink_cells.extend(self.target_cell)
    else:
      sink_cells.append(self.target_cell)
    
    # Deal with east movement
    for i in range(self.num_states):
      if i not in sink_cells:
        T_east[i, i+1] = 0.7
        T_east[i, i] = 0.1
        T_east[i, i+self.size] = 0.1
        T_east[i, i-self.size] = 0.1

    # Deal with north movement
    for i in range(self.num_states):
      if i not in sink_cells:
        T_north[i, i+self.size] = 0.7
        T_north[i, i] = 0.1
        T_north[i, i-1] = 0.1
        T_north[i, i+1] = 0.1

    # Deal with south movement
    for i in range(self.num_states):
      if i not in sink_cells:
        T_south[i, i-self.size] = 0.7
        T_south[i, i] = 0.1
        T_south[i, i-1] = 0.1
        T_south[i, i+1] = 0.1

    # Deal with west movement
    for i in range(self.num_states):
      if i not in sink_cells:
        T_west[i, i-1] = 0.7
        T_west[i, i+ self.size] = 0.1
        T_west[i, i- self.size] = 0.1
        T_west[i, i] = 0.1
    
    for i in sink_cells: # update probabilities for sink cells
      T_east[i,:] = np.zeros((1,self.num_states))
      T_east[i, i] = 1

      T_west[i,:] = np.zeros((1,self.num_states))
      T_west[i, i] = 1

      T_north[i,:] = np.zeros((1,self.num_states))
      T_north[i, i] = 1
      
      T_south[i,:] = np.zeros((1,self.num_states))
      T_south[i, i] = 1
    
    self.sanity_check(T_north, T_south, T_west, T_east)

    self.P = np.stack((T_north, T_east, T_south, T_west)) # NESW
    self.R_new = np.column_stack((r_north, r_east, r_south, r_west)) # NESW

    return
  
  def get_P_and_R(self):
    return self.P, self.R_new

  def run(self, GAMMA, verbose=False):
    start_time = time.time()

    vi = mdptoolbox.mdp.ValueIteration(transitions=self.P, reward=self.R_new, discount=GAMMA)
    if verbose:
      vi.setVerbose()
    vi.run()

    execution_time = time.time() - start_time

    policies_grid = np.rot90(np.flip(np.array(vi.policy).reshape(self.size,self.size), axis=0), k=1,axes=(1,0))
    rewards_grid = np.rot90(np.flip(np.array(vi.V).reshape(self.size, self.size), axis=0), k=1,axes=(1,0))

    return vi.policy, vi.V, policies_grid, rewards_grid, execution_time

# a is mdp toolbox solution, b is your solution, sink_cells are obstacles+target cell state indices
def accuracy(a,b,sink_cells,size):
  num_wrong = 0
  for i in range(a.shape[0]):
    for j in range(a.shape[1]):
      if coordToStateIdx(size, i,j) not in sink_cells:
        if a[i][j] != b[i][j]:
          num_wrong += 1
  return 1 - num_wrong / (a.shape[0] * a.shape[1])

# dijkstra's
dijk_accuracy = []
sizes = [10,20,30,40,50,60,70,80,90,100]
# sizes = [10,40]
dijk_runtime = []
mdp_runtime = []
speed_up = []
num_runs_per_grid = 1
for size in sizes:
  print('running size', size)
  all_mdp_time = 0
  all_dijk_time = 0
  all_speed_ratio = 0
  all_dijk_accuracy = 0
  for i in range(num_runs_per_grid):
    print("iteration", i)
    dijk = Dijkstras(size)
    dijkstras_reward, dijkstras_policy, dijk_time = dijk.run_dijk()
    all_dijk_time += dijk_time
    print("dijkstra's runtime", dijk_time)
    # mdp
    GAMMA = 0.9
    mdp = MDP(dijk.get_size(), dijk.get_env(), dijk.get_obstacles(), dijk.get_target_cell())
    policies, rewards, policy_grid, reward_grid, mdp_time = mdp.run(GAMMA)
    all_mdp_time += mdp_time
    print("mdp runtime", mdp_time)
    mdp_policy = policy_grid
    # accuracy (dijk vs mdp)
    dijkstra_accuracy = accuracy(mdp_policy, dijkstras_policy, dijk.get_sink_cells(), dijk.get_size())
    print("bfs accuracy", dijkstra_accuracy)
    all_dijk_accuracy += dijkstra_accuracy
    speed_ratio = mdp_time/dijk_time
    all_speed_ratio += speed_ratio
    print("speed up ratio", speed_ratio)
  # append averaged metrics
  dijk_runtime.append(all_dijk_time/num_runs_per_grid)
  mdp_runtime.append(all_mdp_time/num_runs_per_grid)
  speed_up.append(all_speed_ratio/num_runs_per_grid)
  dijk_accuracy.append(all_dijk_accuracy/num_runs_per_grid)
  print("===========")

# # save various np to csv
# folder = '/content/drive/MyDrive/S22/ESE 650/ESE650 Final Project/'
# dijkstras_solution = dijk.dijk_policy()
# np.savetxt(folder + "dijkstras_solution.csv", dijkstras_solution, delimiter=",")
# np.savetxt(folder + "env.csv", dijk.get_env(), delimiter=",")
# np.savetxt(folder + "obstacles.csv", dijk.get_obstacles(), delimiter=",")

# plot 50x50
dijk = Dijkstras(50)
dijkstras_reward, dijkstras_policy, dijk_time = dijk.run_dijk()
all_dijk_time += dijk_time
# mdp
GAMMA = 0.9
mdp = MDP(dijk.get_size(), dijk.get_env(), dijk.get_obstacles(), dijk.get_target_cell())
policies, rewards, policy_grid, reward_grid, mdp_time = mdp.run(GAMMA)
mdp_policy = policy_grid
mdp_reward = reward_grid

plt.imshow(mdp_reward); plt.title('MDP Toolbox reward grid'); plt.show()
plt.imshow(dijkstras_reward); plt.title('BFS reward grid'); plt.show()

plt.imshow(mdp_policy); plt.title('MDP Toolbox policy grid'); plt.show()
plt.imshow(dijkstras_policy); plt.title('BFS policy grid'); plt.show()

# metric plots
plt.plot(sizes, dijk_accuracy); plt.title('BFS Accuracy'); plt.xlabel('Size (X,X) of grid'); plt.ylabel('Accuracy'); plt.show()

fig, ax = plt.subplots()
ax.plot(sizes, mdp_runtime, label='MDP Toolbox runtime')
ax.plot(sizes, dijk_runtime, label='BFS runtime')
ax.legend(loc = 'upper left')
plt.title('BFS vs MDP Toolbox runtime')
plt.xlabel('Size (X,X) of grid'); 
plt.ylabel('Runtime');
plt.show()

plt.bar(sizes, speed_up); plt.title('Runtime speedup as N grows'); plt.xlabel('Size (X,X) of grid'); plt.ylabel('BFS runtime/MDP runtime'); plt.show()

# # mdp solution [old]
# mdp_start = time.time()
# r =  np.flip(env,axis=0).flatten()
# num_states = 100 # 1 = (0,0), 2 = (1,0)... 10 = (9,0), 11 = (0,1), 12 = (1,1)...20 = (1,9)... 100 = (9,9)
# num_actions = 4 # 1 = north, 2 = east, 3 = south, 4 = west

# # CREATE P(s' | s,a) = probability of being in some state given initial state and action
# p = np.zeros((num_states, num_states*num_actions))
# obstacle_cells = []
# for i in range(0,100):
#     if (i % 10 == 0) or (i <= 9) or (i % 10 == 9) or (i >= 90) or i == 23 or i == 24 or i == 25 or i == 26 or i == 44 or i == 54 or i == 64 or i == 74 or i == 75 or i == 47 or i == 57:
#         obstacle_cells.append(i)
#     if i in obstacle_cells or i == 18:
#         p[i,i] = 1 # north
#         p[i,i+100] = 1 # east
#         p[i,i+200] = 1 # south
#         p[i,i+300] = 1 # west
        
# # NORTH 
# for i in range(11,89):
#     if i not in obstacle_cells and i != 18:
#         p[i,i-1] = 0.1
#         p[i,i] = 0.1
#         p[i,i+10] = 0.7
#         p[i,i+1] = 0.1

# # EAST
# for i in range(11,89):
#     if i not in obstacle_cells and i != 18:
#         p[i,i-10+100] = 0.1
#         p[i,i+100] = 0.1
#         p[i,i+10+100] = 0.1
#         p[i,i+1+100] = 0.7

# # SOUTH
# for i in range(11,89):
#     if i not in obstacle_cells and i != 18:
#         p[i,i-10+200] = 0.7
#         p[i,i+200] = 0.1
#         p[i,i-1+200] = 0.1
#         p[i,i+1+200] = 0.1

# # WEST
# for i in range(11,89):
#     if i not in obstacle_cells and i != 18:
#         p[i,i-1+300] = 0.7
#         p[i,i+300] = 0.1
#         p[i,i-10+300] = 0.1
#         p[i,i+10+300] = 0.1


# gamma = 0.9
# currV = np.zeros((num_states))
# prevV = np.zeros((num_states))
# currP = np.zeros((num_states))
# prevP = np.zeros((num_states))
# policies = []
# for num_iter in range(50):
#     for i in range(num_states):
#         values = np.zeros((4,1)) # 0 = north, 1 = east, 2 = south, 3 = west
#         for j in range(num_states):
#             values[0] += (p[i,j] * (r[j] + gamma * prevV[i]))
#             values[1] += (p[i,j+100] * (r[j] + gamma * prevV[i]))
#             values[2] += (p[i,j+200] * (r[j] + gamma * prevV[i]))
#             values[3] += (p[i,j+300] * (r[j] + gamma * prevV[i]))
#         currV[i] = max(values)
#         currP[i] = np.argmax(values)
#     prevV = currV
#     policyIndex = np.flip(currP.reshape(10,10), axis=0)
#     policies.append(policyIndex)
# mdp_solution = policies[-1]
# print("mdp solution")
# print(mdp_solution)
# print("time to get solution", time.time() - mdp_start)