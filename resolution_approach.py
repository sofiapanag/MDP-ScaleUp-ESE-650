# -*- coding: utf-8 -*-
"""Resolution Approach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14qSmvDe2YgEu7H7YY2Wzv65HzRKpvwQU
"""

!git clone https://github.com/sawcordwell/pymdptoolbox.git
!pip install pymdptoolbox
import mdptoolbox.example
import time
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# this function converts (x,y) to state index
# state number = coordYcoordX (0,0) is bottom left corner (size-1, size-1) is upper right corner
def coordToStateIdx(x, y, size):
  idx = size*y+x
  return idx
  
# add walls to obstacles list function
def AddWallsToObs(env, size, obstacle_cells):
  for i in range(0,size):
      env[0,i] = -10
      obstacle_cells.append(coordToStateIdx(0,i,size))
      env[i,0] = -10
      obstacle_cells.append(coordToStateIdx(i,0,size))
      env[size-1,i] = -10
      obstacle_cells.append(coordToStateIdx(size-1,i,size))
      env[i,size-1] = -10
      obstacle_cells.append(coordToStateIdx(i,size-1,size))
  return obstacle_cells

# CREATE ENVIRONMENT
def CreateEnv(size, size_new, num_states, num_states_new):
  env = -1 * np.ones((size, size))
  env_new = np.ones((size_new, size_new))

  # obstacle lists
  sink_cells = []
  sink_cells_new = []

  AddWallsToObs(env, size, sink_cells)
      
  # create random clumps of obstacles
  num_obstacles = int(num_states / 30)
  for j in range(num_obstacles):
    obsX = np.random.randint(0,size)
    obsY = np.random.randint(0,size)
    env[obsX, obsY] = -10
    sink_cells.append(coordToStateIdx(obsX, obsY,size))
    for wall in range(3):
      intervalX = np.random.randint(-1,1)
      intervalY = np.random.randint(-1,1)
      currX = obsX+intervalX
      currY = obsY+intervalY
      env[currX, currY] = -10
      sink_cells.append(coordToStateIdx(currX, currY,size))

  # create random target cell
  targetX = np.random.randint(1,size-1)
  targetY = np.random.randint(1,size-1)
  env[targetX,targetY] = 10
  target_cell = size*targetY + targetX
  r = np.flip(env,axis=0).flatten()

  # create environment for small matrix, keep numbers the same
  k = 0
  l = 0
  counter = 0
  for i in range(0, size, 2):
    for j in range(0, size, 2):
      env_new[l][k] = (env[i][j] + env[i+1][j] + env[i][j+1] + env[i+1][j+1]) / 4
      if (env_new[l][k] < -5):      # if more than 2 cells are -10
        env_new[l][k] = -10
        sink_cells_new.append(coordToStateIdx(l, k, size_new))
        counter = counter + 1       # OBSTACLES IN SMALL MATRIX ARE AROUND 100/2500 (4%) - 16% (400/2500)
      elif ((env[i][j] == 10) or (env[i+1][j] == 10) or (env[i][j+1] == 10) or (env[i+1][j+1] == 10)):    # if target is included in group of cells
        env_new[l][k] = 10
        target_cell_new = size_new*k + l
      else:
        env_new[l][k] = -1
      k = int((k + 1)%size_new)
    l = l + 1

  # new matrix add walls to obstacles
  AddWallsToObs(env_new, size_new, sink_cells_new)

  plt.show()
  plt.imshow(env)
  plt.title("Environment")
  plt.show()
  plt.imshow(env_new)
  plt.title("New Environment")
  plt.show()
  
  return env, env_new, sink_cells, sink_cells_new, target_cell, target_cell_new

# R MATRICES
def CreateRMatrices(env, env_new, num_states, num_states_new, sink_cells, sink_cells_new, target_cell, target_cell_new):
  # Create R_new to pass to built-in Python function
  paddedR = np.pad(env, 1, mode='constant', constant_values=-10)
  paddedR_new = np.pad(env_new, 1, mode='constant', constant_values=-10)

  # probability matrices
  R_north = get_R_direction(paddedR, 0.7, 0.0, 0.1, 0.1, 0.1)
  r_north = updateRObstacles(R_north.flatten(), num_states, sink_cells, target_cell)   # flatten() puts elements next to each other

  R_south = get_R_direction(paddedR, 0.0, 0.7, 0.1, 0.1, 0.1)
  r_south = updateRObstacles(R_south.flatten(), num_states, sink_cells, target_cell)

  R_west = get_R_direction(paddedR, 0.1, 0.1, 0.7, 0.0, 0.1)
  r_west = updateRObstacles(R_west.flatten(), num_states, sink_cells, target_cell)

  R_east = get_R_direction(paddedR, 0.1, 0.1, 0.0, 0.7, 0.1)
  r_east = updateRObstacles(R_east.flatten(), num_states, sink_cells, target_cell)

  # new probability matrices
  R_north_new = get_R_direction(paddedR_new, 0.7, 0.0, 0.1, 0.1, 0.1)
  r_north_new = updateRObstacles(R_north_new.flatten(), num_states_new, sink_cells_new, target_cell_new)

  R_south_new = get_R_direction(paddedR_new, 0.0, 0.7, 0.1, 0.1, 0.1)
  r_south_new = updateRObstacles(R_south_new.flatten(), num_states_new, sink_cells_new, target_cell_new)

  R_west_new = get_R_direction(paddedR_new, 0.1, 0.1, 0.7, 0.0, 0.1)
  r_west_new = updateRObstacles(R_west_new.flatten(), num_states_new, sink_cells_new, target_cell_new)

  R_east_new = get_R_direction(paddedR_new, 0.1, 0.1, 0.0, 0.7, 0.1)
  r_east_new = updateRObstacles(R_east_new.flatten(), num_states_new, sink_cells_new, target_cell_new)

  r = np.flip(env,axis=0).flatten()

  return r_north, r_south, r_east, r_west, r_north_new, r_south_new, r_east_new, r_west_new

# TRANSITION MATRICES
def TransitionMatrices(num_states, size, sink_cells):
  # Define all states ~ Transition Matrix
  T_north = np.zeros((num_states,num_states))
  T_east = np.zeros((num_states,num_states))
  T_south = np.zeros((num_states,num_states))
  T_west = np.zeros((num_states,num_states))

  # Deal with east movement
  for i in range(size+1,num_states-size-1):
    if i not in sink_cells:   # sink cells include walls, obstacles, and target
      T_east[i, i+1] = 0.7
      T_east[i, i] = 0.1
      T_east[i, i-size] = 0.1
      T_east[i, i+size] = 0.1

  # Deal with north movement
  for i in range(size+1,num_states-size-1):
    if i not in sink_cells:
      T_north[i, i] = 0.1
      T_north[i, i-1] = 0.1
      T_north[i, i+1] = 0.1
      T_north[i, i+size] = 0.7

  # Deal with south movement
  for i in range(size+1,num_states-size-1):
    if i not in sink_cells:
      T_south[i, i-size] = 0.7
      T_south[i, i] = 0.1
      T_south[i, i-1] = 0.1
      T_south[i, i+1] = 0.1

  # Deal with west movement
  for i in range(size+1,num_states-size-1):
    if i not in sink_cells:
      T_west[i, i-1] = 0.7
      T_west[i, i-size] = 0.1
      T_west[i, i] = 0.1
      T_west[i, i+size] = 0.1

  # update probabilities for sink cells
  for i in sink_cells:
    T_east[i,:] = np.zeros((1,num_states))
    T_east[i, i] = 1

    T_west[i,:] = np.zeros((1,num_states))
    T_west[i, i] = 1

    T_north[i,:] = np.zeros((1,num_states))
    T_north[i, i] = 1
    
    T_south[i,:] = np.zeros((1,num_states))
    T_south[i, i] = 1
  return T_east, T_west, T_north, T_south

# Update Reward of Obstacles
def updateRObstacles(r, num_states, obstacles, target_cell):
  for i in range(num_states):
    if i in obstacles:
      r[i] = -10
    if i == target_cell:
      r[i] = 10
  return r

def get_R_direction(R, prob_north, prob_south, prob_west, prob_east, prob_same):
  return R[:-2, 1:-1] * prob_north + R[2:, 1:-1] * prob_south + R[1:-1, :-2] * prob_west + R[1:-1, 2:] * prob_east + R[1:-1, 1:-1] * prob_same

# Sanity check that all rows of T add up to one
def SanityCheck(num_states, T_east, T_west, T_north, T_south):
  for i in range(num_states): 
    summed = np.sum(T_east[i])
    if summed < 0.99 or summed > 1.01:
      print("east", i, T_east[i])
    
    summed = np.sum(T_north[i])
    if summed < 0.99 or summed > 1.01:
      print("north", i, T_north[i])
    
    summed = np.sum(T_west[i])
    if summed < 0.99 or summed > 1.01:
      print("west", i, T_west[i])
    
    summed = np.sum(T_south[i])
    if summed < 0.99 or summed > 1.01:
      print("south", i, T_south[i])

# POLICY ITERATION
def PolicyIteration(size, T_east, T_west, T_north, T_south, r_north, r_east, r_south, r_west):
  # Instructinos on inputs: https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP
  start_time = time.time()
  P = np.stack((T_north, T_east, T_south, T_west)) # NESW
  #print(P.shape)

  R_new = np.column_stack((r_north, r_east, r_south, r_west)) # NESW
  #print(R_new.shape)

  # Hyperparameters
  GAMMA = 0.9

  vi = mdptoolbox.mdp.ValueIteration(transitions=P, reward=R_new, discount=GAMMA)
  #vi.setVerbose()
  vi.run()
  #print('Policy', vi.policy)
  #print('Value', vi.V)

  policies = np.rot90(np.flip(np.array(vi.policy).reshape(size,size), axis=0), k=1,axes=(1,0))
  #print(policies)
  rewards = np.rot90(np.flip(np.array(vi.V).reshape(size,size), axis=0), k=1,axes=(1,0))
  #print(rewards.shape)
  #print("max reward", np.max(rewards))
  
  return rewards, start_time, policies

# Get the accuracy by comparing cell by cell the resulting matrices
def get_accuracy(a, b, obstacles):  # a is reference solution, b is your solution, sink_cells are obstacles+target cell
  s = a.shape
  c = 0
  for i in range(a.shape[0]):
    for j in range(a.shape[1]):
      if (j*s[1] + i) not in obstacles:
        c += a[i, j] == b[i, j]
  return c / (a.shape[0] * a.shape[1] - len(np.unique(obstacles)))

# PLOT THE RESULTING MAPS
def MapPlots(size, reference_rewards, expanded_resulting_rewards, reference_policies, expanded_resulting_policies, env):
  # Plotting and downloading environment map 
  plt.imshow(env)
  plt.title("Initial Map")
  plt.show()
  #plt.savefig("Initial Map %i.png" % size)
  #files.download("Initial Map %i.png" % size)

  # Plotting and downloading reference map 
  plt.imshow(reference_rewards)
  plt.title("True Reward Grid")
  plt.show()
  #plt.savefig("True Reward Grid %i.png" % size)
  #files.download("True Reward Grid %i.png" % size) 
  #print(reference_start_time)
  #print("toolbox time in seconds", reference_time)

  # Plotting and downloading resulting map 
  plt.imshow(expanded_resulting_rewards)
  plt.title("Reconstructed Reward Grid")
  plt.show()
  #plt.savefig("Reconstructed Reward Grid %i.png" % size)
  #files.download("Reconstructed Reward Grid %i.png" % size) 
  #print(resulting_start_time)
  #print("toolbox time in seconds", resulting_time)

  # Plotting and downloading reference policies 
  plt.imshow(reference_policies)
  plt.title("True Policy Grid")
  plt.show()
  #plt.savefig("True Policy Grid %i.png" % size)
  #files.download("True Policy Grid %i.png" % size)

  # Plotting and downloading resulting map 
  plt.imshow(expanded_resulting_policies)
  plt.title("Reconstructed Policy Grid")
  plt.show()
  #plt.savefig("Reconstructed Policy Grid %i.png" % size)
  #files.download("Reconstructed Policy Grid %i.png" % size)

# RUN MDP FOR MATRIX (SIZE,SIZE) 
def MainLoopFunction(size):
  num_states = size ** 2
  num_actions = 4 # 1 = north, 2 = east, 3 = south, 4 = west

  # CHANGE RESOLUTION
  n = 2
  #n = np.log10(size)  # resolution blocks size
  #size_new = int(size / n)      # generalize calculation
  size_new = int(size / 2)
  num_states_new = int(size_new ** 2)

  env, env_new, sink_cells, sink_cells_new, target_cell, target_cell_new = CreateEnv(size, size_new, num_states, num_states_new)
  r_north, r_south, r_east, r_west, r_north_new, r_south_new, r_east_new, r_west_new = CreateRMatrices(env, env_new, num_states, num_states_new, sink_cells, sink_cells_new, target_cell, target_cell_new)

  # obstacles and target cells are sink cells 
  sink_cells.append(target_cell)
  sink_cells_new.append(target_cell_new)

  T_east, T_west, T_north, T_south = TransitionMatrices(num_states, size, sink_cells)
  T_east_new, T_west_new, T_north_new, T_south_new = TransitionMatrices(num_states_new, size_new, sink_cells_new)

  SanityCheck(num_states, T_east, T_west, T_north, T_south)
  SanityCheck(num_states_new, T_east_new, T_west_new, T_north_new, T_south_new)

  reference_rewards, reference_start_time, reference_policies = PolicyIteration(size, T_east, T_west, T_north, T_south, r_north, r_east, r_south, r_west)
  reference_time = time.time() - reference_start_time
  resulting_rewards, resulting_start_time, resulting_policies = PolicyIteration(size_new, T_east_new, T_west_new, T_north_new, T_south_new, r_north_new, r_east_new, r_south_new, r_west_new)
  resulting_time = time.time() - resulting_start_time

  # EXPANDING RESULTING MAPS
  expanded_resulting_rewards = np.zeros((size,size))
  expanded_resulting_policies = np.zeros((size,size))

  expanded_resulting_rewards = np.repeat(resulting_rewards, 2, 0)
  expanded_resulting_rewards = np.repeat(expanded_resulting_rewards, 2, 1)

  expanded_resulting_policies = np.repeat(resulting_policies, 2, 0)
  expanded_resulting_policies = np.repeat(expanded_resulting_policies, 2, 1)

  accuracy = get_accuracy(expanded_resulting_policies, reference_policies, sink_cells)

  return accuracy, reference_time, resulting_time, reference_rewards, expanded_resulting_rewards, reference_policies, expanded_resulting_policies, env

# RUNNING FUNCTIONS 

# Run for multiple size cases and plot results
def RunMainForAll():
  true_time = []
  reconstr_time = []
  acc_list = []
  s_list = []

  for s in [12, 20, 32, 40, 52, 60, 72, 80, 92, 100]:    # has to be divided by 4
    sum_true_time = 0
    sum_reconstr_time = 0
    sum_acc = 0
    iters = 5
    for j in range(iters):
      accuracy, reference_time, resulting_time, reference_rewards, expanded_resulting_rewards, reference_policies, expanded_resulting_policies, env = MainLoopFunction(s)
      MapPlots(s, reference_rewards, expanded_resulting_rewards, reference_policies, expanded_resulting_policies, env)
      sum_true_time += reference_time
      sum_reconstr_time += resulting_time
      sum_acc += accuracy
    true_time.append(sum_true_time / iters)
    reconstr_time.append(sum_reconstr_time / iters)
    acc_list.append(int(sum_acc / iters * 100))
    s_list.append(s)
    print(true_time, reconstr_time, acc_list)

  plt.show()

  plt.plot(s_list, acc_list); 
  plt.title('Accuracy'); 
  plt.xlabel('Size (X,X) of grid'); 
  plt.ylabel('% Accuracy'); 
  plt.show()

  plt.plot(s_list, true_time, label='MDP'); 
  plt.plot(s_list, reconstr_time, label='Reduced Resolution'); 
  plt.xlabel('Size (X,X) of grid'); 
  plt.ylabel('Runtime (seconds)'); 
  plt.title('Runtime as N grows'); 
  plt.legend(); 
  plt.show()

  plt.bar(s_list, np.divide(true_time, reconstr_time)); 
  plt.xlabel('Size (X,X) of grid'); 
  plt.title('Runtime speedup as X grows'); 
  plt.ylabel('Reduced Resolution runtime/MDP runtime'); 
  plt.show()

# Run once for matrix (size,size) and plot results
def RunMainOnce(s):
  accuracy, reference_time, resulting_time, reference_rewards, expanded_resulting_rewards, reference_policies, expanded_resulting_policies, env = MainLoopFunction(s)
  MapPlots(s, reference_rewards, expanded_resulting_rewards, reference_policies, expanded_resulting_policies, env)

RunMainForAll()